#!/bin/bash

# Enhanced GraphRAG Pipeline for feihm project
# åŸºäºŽlecterzæž¶æž„å®Œå–„çš„feihm GraphRAGæµæ°´çº¿

set -e

# é…ç½®å‚æ•°
export CUDA_VISIBLE_DEVICES=1,4,5,6
WORLD_SIZE=4
export OMP_NUM_THREADS=64
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:False

# è·¯å¾„é…ç½®
DATASET_PATH=~/llm-fei/Data/NQ/contriever_nq_all_train/train.json
MODEL_PATH=/home/feihm/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28
OUTPUT_DIR=./enhanced_graphrag_output
EXTRACTION_DIR=${OUTPUT_DIR}/extraction
GRAPH_DIR=${OUTPUT_DIR}/graph
QA_DIR=${OUTPUT_DIR}/qa

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p ${EXTRACTION_DIR}
mkdir -p ${GRAPH_DIR}
mkdir -p ${QA_DIR}

echo "ðŸš€ Starting Enhanced feihm GraphRAG Pipeline - Individual Question Graphs..."
echo "ðŸ“ Architecture: Each question gets its own knowledge graph (N questions = N graphs)"

# æ­¥éª¤1: å¢žå¼ºå®žä½“å…³ç³»æå–ï¼ˆåŸºäºŽlecterzçš„gleaningæœºåˆ¶ï¼‰
echo "ðŸ“‹ Step 1: Enhanced Entity and Relationship Extraction with Gleaning"
python enhanced_extract.py \
    --data_file ${DATASET_PATH} \
    --model_name ${MODEL_PATH} \
    --world_size ${WORLD_SIZE} \
    --dest_dir ${EXTRACTION_DIR} \
    --num_proc 32 \
    --batch_size 16 \
    --max_new_tokens 2048

# æ£€æŸ¥æå–æ˜¯å¦æˆåŠŸ
if [ ! -f "${EXTRACTION_DIR}/enhanced_extraction_results.jsonl" ]; then
    echo "âŒ Enhanced extraction failed!"
    exit 1
fi

echo "âœ… Step 1 completed: Enhanced extraction with gleaning mechanism"

# æ­¥éª¤2: ä¸ºæ¯ä¸ªé—®é¢˜æž„å»ºç‹¬ç«‹çš„çŸ¥è¯†å›¾è°±
echo "ðŸ”— Step 2: Building Individual Knowledge Graphs for Each Question"
python graph_builder.py \
    --extraction_file ${EXTRACTION_DIR}/enhanced_extraction_results.jsonl \
    --output_dir ${GRAPH_DIR} \
    --similarity_threshold 0.7 \
    --similarity_top_k 10 \
    --enable_community \
    --embedding_model all-MiniLM-L6-v2

# æ£€æŸ¥å›¾æž„å»ºæ˜¯å¦æˆåŠŸ
if [ ! -f "${GRAPH_DIR}/overall_statistics.json" ]; then
    echo "âŒ Question graph building failed!"
    exit 1
fi

echo "âœ… Step 2 completed: Individual question graphs built"

# æ˜¾ç¤ºå›¾ç»Ÿè®¡ä¿¡æ¯
if [ -f "${GRAPH_DIR}/overall_statistics.json" ]; then
    echo "ðŸ“Š Question Graphs Statistics:"
    cat ${GRAPH_DIR}/overall_statistics.json | python -m json.tool
fi

# æ­¥éª¤3: æµ‹è¯•å¤šé—®é¢˜å›¾è°±æ£€ç´¢ç³»ç»Ÿ
echo "ðŸ” Step 3: Testing Multi-Question Graph Retrieval System"

# åˆ›å»ºæµ‹è¯•æŸ¥è¯¢
TEST_QUERIES=(
    "What is the capital of France?"
    "Who invented the telephone?"
    "What causes earthquakes?"
    "How does photosynthesis work?"
    "When was the Internet created?"
    "What is machine learning?"
    "How do vaccines work?"
    "What is climate change?"
)

echo "Testing retrieval with sample queries using different modes..."

# é¦–å…ˆæ˜¾ç¤ºé—®é¢˜å›¾è°±ç»Ÿè®¡
echo "--- Question Graph Statistics ---"
python graphrag_retriever.py \
    --graphs_dir ${GRAPH_DIR} \
    --query "dummy" \
    --stats \
    --search_mode single_best 2>/dev/null | head -10

# æµ‹è¯•å•ä¸€æœ€ä½³é—®é¢˜å›¾è°±æœç´¢
echo "--- Testing Single Best Question Graph Search ---"
for query in "${TEST_QUERIES[@]:0:3}"; do
    echo "Single Best Query: $query"
    python graphrag_retriever.py \
        --graphs_dir ${GRAPH_DIR} \
        --query "$query" \
        --search_mode single_best \
        --max_tokens 2000
    echo "---"
done

# æµ‹è¯•å¤šé—®é¢˜å›¾è°±æœç´¢
echo "--- Testing Multi-Question Graph Search ---"
for query in "${TEST_QUERIES[@]:3:5}"; do
    echo "Multi-Question Query: $query"
    python graphrag_retriever.py \
        --graphs_dir ${GRAPH_DIR} \
        --query "$query" \
        --search_mode multi_question \
        --max_questions 3 \
        --max_tokens 4000
    echo "---"
done

# æ­¥éª¤4: QAç³»ç»Ÿæµ‹è¯•ï¼ˆåŸºäºŽå¤šé—®é¢˜å›¾è°±æ£€ç´¢ï¼‰
echo "ðŸ’¬ Step 4: Multi-Question Graph QA System Test"

# æµ‹è¯•ä¸åŒæœç´¢æ¨¡å¼çš„QAæ•ˆæžœ
echo "Testing QA with single best question graph mode:"
python graphrag_qa.py single \
    --graphs_dir ${GRAPH_DIR} \
    --model_name ${MODEL_PATH} \
    --world_size ${WORLD_SIZE} \
    --query "What is the capital of France?" \
    --search_mode single_best

echo "Testing QA with multi-question graph mode:"
python graphrag_qa.py single \
    --graphs_dir ${GRAPH_DIR} \
    --model_name ${MODEL_PATH} \
    --world_size ${WORLD_SIZE} \
    --query "How do vaccines work?" \
    --search_mode multi_question \
    --max_questions 3

echo "Testing QA with extended multi-question search:"
python graphrag_qa.py single \
    --graphs_dir ${GRAPH_DIR} \
    --model_name ${MODEL_PATH} \
    --world_size ${WORLD_SIZE} \
    --query "What causes climate change?" \
    --search_mode multi_question \
    --max_questions 5

echo "âœ… Step 4 completed: QA system tested with multiple search modes"

# æ­¥éª¤5: æ•°æ®é›†è¯„ä¼°ï¼ˆå¯é€‰ï¼‰
if [ "$1" = "--full_eval" ]; then
    echo "ðŸ“Š Step 5: Full Dataset Evaluation"
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®é›†ï¼ˆå–å‰100ä¸ªæ ·æœ¬ï¼‰
    echo "Preparing test dataset..."
    head -n 100 ${DATASET_PATH} > ${QA_DIR}/test_dataset.jsonl
    
    # æµ‹è¯•ä¸åŒæœç´¢æ¨¡å¼
    for mode in "local" "global" "hybrid"; do
        echo "Evaluating with ${mode} search mode..."
        python graphrag_qa.py eval \
            --graph_dir ${GRAPH_DIR} \
            --model_name ${MODEL_PATH} \
            --world_size ${WORLD_SIZE} \
            --dataset_file ${QA_DIR}/test_dataset.jsonl \
            --output_file ${QA_DIR}/evaluation_results_${mode}.jsonl \
            --search_mode ${mode}
    done
    
    echo "âœ… Step 5 completed: Full evaluation with all search modes"
    
    # æ¯”è¾ƒä¸åŒæœç´¢æ¨¡å¼çš„æ•ˆæžœ
    echo "ðŸ“ˆ Evaluation Results Comparison:"
    for mode in "local" "global" "hybrid"; do
        if [ -f "${QA_DIR}/evaluation_results_${mode}.jsonl" ]; then
            echo "=== ${mode} Search Mode ==="
            python -c "
import json
results = []
with open('${QA_DIR}/evaluation_results_${mode}.jsonl', 'r') as f:
    for line in f:
        results.append(json.loads(line))

total = len(results)
fail_responses = [r for r in results if r['response'] == 'Sorry, I'\''m not able to provide an answer to that question.']
non_fail = total - len(fail_responses)

print(f'Total questions: {total}')
print(f'Successful responses: {non_fail}/{total} ({non_fail/total*100:.1f}%)')

if non_fail > 0:
    successful_results = [r for r in results if r['response'] != 'Sorry, I'\''m not able to provide an answer to that question.']
    avg_length = sum(len(r['response']) for r in successful_results) / len(successful_results)
    print(f'Average response length: {avg_length:.1f} characters')
    
    # ç®€å•çš„åŒ…å«ç­”æ¡ˆæ£€æŸ¥
    contains_answer = 0
    for r in successful_results:
        response_lower = r['response'].lower()
        for answer in r.get('ground_truth', []):
            if answer.lower() in response_lower:
                contains_answer += 1
                break
    
    if successful_results:
        print(f'Responses containing ground truth: {contains_answer}/{len(successful_results)} ({contains_answer/len(successful_results)*100:.1f}%)')
"
            echo ""
        fi
    done
    
else
    echo "â„¹ï¸  Skipping full evaluation. Use '--full_eval' flag to run complete evaluation."
fi

# æ­¥éª¤6: åˆ›å»ºç¤ºä¾‹é—®é¢˜æ–‡ä»¶å¹¶æµ‹è¯•æ‰¹é‡å¤„ç†
echo "ðŸ“ Step 6: Testing Batch Processing"

# åˆ›å»ºç¤ºä¾‹é—®é¢˜æ–‡ä»¶
cat > ${QA_DIR}/sample_questions.txt << EOF
What is artificial intelligence?
How do neural networks work?
What is the difference between machine learning and deep learning?
What causes global warming?
How do electric cars work?
EOF

# æµ‹è¯•æ‰¹é‡å¤„ç†
python graphrag_qa.py batch \
    --graph_dir ${GRAPH_DIR} \
    --model_name ${MODEL_PATH} \
    --world_size ${WORLD_SIZE} \
    --questions_file ${QA_DIR}/sample_questions.txt \
    --output_file ${QA_DIR}/batch_results.jsonl \
    --search_mode hybrid

echo "âœ… Step 6 completed: Batch processing tested"

# æ€»ç»“
echo ""
echo "ðŸŽ‰ Enhanced feihm GraphRAG Pipeline Completed!"
echo "ðŸ“ Output Structure:"
echo "   ${OUTPUT_DIR}/"
echo "   â”œâ”€â”€ extraction/"
echo "   â”‚   â””â”€â”€ enhanced_extraction_results.jsonl    # å¢žå¼ºçš„å®žä½“å…³ç³»æå–ç»“æžœ"
echo "   â”œâ”€â”€ graph/"
echo "   â”‚   â”œâ”€â”€ nx_data.graphml                       # NetworkXå›¾ï¼ˆlecterzå…¼å®¹æ ¼å¼ï¼‰"
echo "   â”‚   â”œâ”€â”€ knowledge_graph.gpickle               # å¿«é€ŸåŠ è½½æ ¼å¼"
echo "   â”‚   â”œâ”€â”€ entities.json                         # å®žä½“æ•°æ®"
echo "   â”‚   â”œâ”€â”€ relationships.json                    # å…³ç³»æ•°æ®"
echo "   â”‚   â”œâ”€â”€ entity_vectors.npz                    # å®žä½“å‘é‡"
echo "   â”‚   â”œâ”€â”€ relationship_vectors.npz              # å…³ç³»å‘é‡"
echo "   â”‚   â””â”€â”€ graph_stats.json                      # å›¾ç»Ÿè®¡ä¿¡æ¯"
echo "   â””â”€â”€ qa/"
echo "       â”œâ”€â”€ test_dataset.jsonl                    # æµ‹è¯•æ•°æ®é›†"
echo "       â”œâ”€â”€ evaluation_results_*.jsonl           # è¯„ä¼°ç»“æžœ"
echo "       â”œâ”€â”€ sample_questions.txt                 # ç¤ºä¾‹é—®é¢˜"
echo "       â””â”€â”€ batch_results.jsonl                  # æ‰¹é‡å¤„ç†ç»“æžœ"

echo ""
echo "ðŸ”§ Usage Examples:"
echo ""
echo "# å•ä¸ªé—®é¢˜ï¼ˆä¸åŒæœç´¢æ¨¡å¼ï¼‰:"
echo "python graphrag_qa.py single --graph_dir ${GRAPH_DIR} --query 'Your question here' --search_mode hybrid"
echo "python graphrag_qa.py single --graph_dir ${GRAPH_DIR} --query 'Your question here' --search_mode local"
echo "python graphrag_qa.py single --graph_dir ${GRAPH_DIR} --query 'Your question here' --search_mode global"
echo ""
echo "# æ£€ç´¢æµ‹è¯•:"
echo "python graphrag_retriever.py --graph_dir ${GRAPH_DIR} --query 'Your query here' --search_mode hybrid"
echo ""
echo "# æ•°æ®é›†è¯„ä¼°:"
echo "python graphrag_qa.py eval --graph_dir ${GRAPH_DIR} --dataset_file your_data.jsonl --output_file results.jsonl"
echo ""
echo "# æ‰¹é‡å¤„ç†:"
echo "python graphrag_qa.py batch --graph_dir ${GRAPH_DIR} --questions_file questions.txt --output_file results.jsonl"

echo ""
echo "ðŸ†š Key Improvements over Original feihm:"
echo "   âœ“ Multi-round gleaning extraction (based on lecterz)"
echo "   âœ“ lecterz-style entity/relationship merging"
echo "   âœ“ Community detection with Louvain algorithm"
echo "   âœ“ Multi-mode retrieval (local/global/hybrid)"
echo "   âœ“ Vector-based similarity search"
echo "   âœ“ lecterz-compatible graph storage format"
echo "   âœ“ Comprehensive evaluation framework"
echo ""
echo "ðŸ“ˆ Expected Performance Improvement:"
echo "   Original feihm exact_match: 0.33"
echo "   Enhanced version: Expected significant improvement with multi-mode retrieval"